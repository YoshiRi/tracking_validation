{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto update python file\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sys path\n",
    "# set path\n",
    "import sys\n",
    "sys.path.append('../tracking_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import tempfile\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m[INFO 1685032682.692980922] [rosbag2_storage]: Opened database '/home/yoshiri/Downloads/temp/testcase1/scenario_0_0.db3' for READ_ONLY. (open() at ./src/rosbag2_storage_default_plugins/sqlite/sqlite_storage.cpp:204)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# sample rosbag loading\n",
    "from rosbag_parser import get_topics_and_tf\n",
    "#from tracking_parser import DetctionAndTrackingParser\n",
    "\n",
    "rosbag_file = '/home/yoshiri/Downloads/temp/testcase1/scenario_0_0.db3'\n",
    "topic_names = [\"/perception/object_recognition/detection/objects\", \"/perception/object_recognition/tracking/objects\"]\n",
    "topics, tf = get_topics_and_tf(rosbag_file, topic_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Test\n",
    "\n",
    "## Step1: CheckModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample objects for testing and evaluation\n",
    "sample_tracked_objects = topics[topic_names[1]][0]\n",
    "sample_detected_objects = topics[topic_names[0]][0]\n",
    "\n",
    "import pickle\n",
    "sample_data = {'tracked_objects': sample_tracked_objects, 'detected_objects': sample_detected_objects}\n",
    "with open('../test/test_data/sample_objects', 'wb') as f:\n",
    "    pickle.dump(sample_data,f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample objects\n",
    "import pickle\n",
    "def load_sample_objects():\n",
    "    with open('../test/test_data/sample_objects', 'rb') as f:\n",
    "        sample_data = pickle.load(f)\n",
    "    sample_tracked_objects = sample_data['tracked_objects']\n",
    "    sample_detected_objects = sample_data['detected_objects']\n",
    "    return sample_tracked_objects, sample_detected_objects\n",
    "\n",
    "sample_tracked_objects, sample_detected_objects = load_sample_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_utils import list_dynamic_object_from_ros_msg\n",
    "import driving_log_replayer.perception_eval_conversions as eval_conversions\n",
    "from perception_eval.common.status import FrameID\n",
    "from autoware_auto_perception_msgs.msg import TrackedObject, TrackedObjects, DetectedObject, DetectedObjects, PredictedObject, PredictedObjects\n",
    "from perception_eval.common.object import DynamicObject\n",
    "from perception_eval.common.dataset import FrameGroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<perception_eval.common.object.DynamicObject at 0x7f74f7ef7bb0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tracked obj to dynamic obj\n",
    "def tracked_obj_to_dynamic_obj(tracked_obj: TrackedObjects) -> List[DynamicObject]:\n",
    "    unix_time: int = eval_conversions.unix_time_from_ros_msg(tracked_obj.header)\n",
    "    frame_id: FrameID = FrameID.from_value(tracked_obj.header.frame_id)\n",
    "    return list_dynamic_object_from_ros_msg(frame_id, unix_time, tracked_obj.objects)\n",
    "\n",
    "msg = sample_tracked_objects[1]\n",
    "tracked_obj_to_dynamic_obj(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<perception_eval.common.dataset.FrameGroundTruth at 0x7f74f7e031f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tracked obj to ground truth frame\n",
    "def tracked_obj_to_frame_ground_truth(tracked_obj: TrackedObjects, frame_name: str) -> FrameGroundTruth:\n",
    "    unix_time: int = eval_conversions.unix_time_from_ros_msg(tracked_obj.header)\n",
    "    dynamic_objects: List[DynamicObject] = tracked_obj_to_dynamic_obj(tracked_obj)\n",
    "    return FrameGroundTruth(unix_time, frame_name, dynamic_objects)\n",
    "\n",
    "msg = sample_tracked_objects[1]\n",
    "tracked_obj_to_frame_ground_truth(msg, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(autoware_auto_perception_msgs.msg.TrackedObjectKinematics(pose_with_covariance=geometry_msgs.msg.PoseWithCovariance(pose=geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)), covariance=array([0.2097757 , 0.09576888, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09576888, 0.07551026, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01      ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01      , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01      , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.022302  ])), orientation_availability=1, twist_with_covariance=geometry_msgs.msg.TwistWithCovariance(twist=geometry_msgs.msg.Twist(linear=geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=0.0), angular=geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=0.0)), covariance=array([0.86105083, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01      , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01      ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01      , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01      , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20699994])), acceleration_with_covariance=geometry_msgs.msg.AccelWithCovariance(accel=geometry_msgs.msg.Accel(linear=geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=0.0), angular=geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=0.0)), covariance=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])), is_stationary=False),\n",
       " autoware_auto_perception_msgs.msg.DetectedObjectKinematics(pose_with_covariance=geometry_msgs.msg.PoseWithCovariance(pose=geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364151727717), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)), covariance=array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1.])), has_position_covariance=False, orientation_availability=0, twist_with_covariance=geometry_msgs.msg.TwistWithCovariance(twist=geometry_msgs.msg.Twist(linear=geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=0.0), angular=geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=0.0)), covariance=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])), has_twist=False, has_twist_covariance=False))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tracked_objects[1].objects[0].kinematics, sample_detected_objects[1].objects[0].kinematics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m[INFO 1685294132.139797531] [rosbag2_storage]: Opened database '/home/yoshiri/Downloads/temp/testcase1/scenario_0_0.db3' for READ_ONLY. (open() at ./src/rosbag2_storage_default_plugins/sqlite/sqlite_storage.cpp:204)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from rosbag_parser import get_topics_as_dict\n",
    "\n",
    "prediction_topic = \"/perception/object_recognition/objects\"\n",
    "pred_topic_dicts = get_topics_as_dict(rosbag_file, [prediction_topic])\n",
    "\n",
    "sample_predicted_objects = pred_topic_dicts[prediction_topic][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_obj = sample_predicted_objects[1].objects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735)),\n",
       " geometry_msgs.msg.Pose(position=geometry_msgs.msg.Point(x=3759.5928970352898, y=73739.71130046145, z=20.556364059448242), orientation=geometry_msgs.msg.Quaternion(x=0.0, y=0.0, z=-0.9713731197630094, w=0.2375589657366735))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_obj.kinematics.predicted_paths[0].path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
